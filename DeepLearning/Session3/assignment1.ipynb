{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification: sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will use of this problem is known as the Stanford Sentiment Treebank. Movie reviews with one sentence per review:\n",
    "* `sst.bin.*` with binary labels: negative or positive\n",
    "* `sst.fine.*` with fine-grained labels (very negative, negative, neutral, positive, very positive),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.utils.data_utils import get_file\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:      6920   Mean sentence length: 19.3\n",
      "Validation: 872\n",
      "Test:       1821\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/sst.bin.train\", \"r\") as f:\n",
    "    train = [(int(x.split()[0]), x.split()[1:]) for x in f.readlines()]\n",
    "with open(\"data/sst.bin.val\", \"r\") as f:\n",
    "    val = [(int(x.split()[0]), x.split()[1:]) for x in f.readlines()]\n",
    "with open(\"data/sst.bin.test\", \"r\") as f:\n",
    "    test = [(x.split()[1:]) for x in f.readlines()]\n",
    "print(\"Train:     \", len(train), \"  Mean sentence length:\", np.mean([len(x[1]) for x in train]).round(2))\n",
    "print(\"Validation:\", len(val))\n",
    "print(\"Test:      \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/sst.bin.train\", \"r\") as f:\n",
    "    sent_train = [x[2:-1] for x in f.readlines()]\n",
    "with open(\"data/sst.bin.val\", \"r\") as f:\n",
    "    sent_val = [x[2:-1] for x in f.readlines()]\n",
    "with open(\"data/sst.bin.test\", \"r\") as f:\n",
    "    sent_test = [x[2:-1] for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(corpus, window_size, V):\n",
    "    maxlen = window_size*2\n",
    "    for words in corpus:\n",
    "        L = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            contexts = []\n",
    "            labels   = []            \n",
    "            s = index - window_size\n",
    "            e = index + window_size + 1\n",
    "            \n",
    "            contexts.append([words[i] for i in range(s, e) if 0 <= i < L and i != index])\n",
    "            labels.append(word)\n",
    "\n",
    "            x = sequence.pad_sequences(contexts, maxlen=maxlen)\n",
    "            y = np_utils.to_categorical(labels, V)\n",
    "            yield (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "\n",
    "# calculate word frequencies\n",
    "word_frequencies = Counter(itertools.chain(\n",
    "    *((word for word in sample[1]) for sample in train)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 14828\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Vocabulary size:\", len(word_frequencies))\n",
    "\n",
    "plt.plot([x[1] for x in word_frequencies.most_common()[::-1]])\n",
    "plt.ylim(0, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing words\n",
    "PAD = 0 # padding\n",
    "UNK = 1 # unknown word\n",
    "vocab = dict()\n",
    "\n",
    "word_index = 2\n",
    "for w, c in word_frequencies.most_common():\n",
    "    if c > 4:\n",
    "        vocab[w] = word_index\n",
    "        word_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change words with indices\n",
    "\n",
    "train_X = [[vocab.get(x, UNK) for x in sample[1]]\n",
    "                    for sample in train]\n",
    "train_y = [sample[0] for sample in train]\n",
    "\n",
    "max_len = np.sort([len(x) for x in train_X])\n",
    "\n",
    "val_X = [[vocab.get(x, UNK) for x in sample[1]]\n",
    "                    for sample in val]\n",
    "val_y = [sample[0] for sample in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = keras.preprocessing.sequence.pad_sequences(train_X, value=PAD)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "val_X = keras.preprocessing.sequence.pad_sequences(val_X, value=PAD)\n",
    "val_y = np.array(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6920, 52), (6920,), (872, 47), (872,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape, val_X.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPool1D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 32)          92416     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 145,717\n",
      "Trainable params: 145,717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(word_index, embedding_vecor_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6920 samples, validate on 872 samples\n",
      "Epoch 1/10\n",
      "6920/6920 [==============================] - 18s 3ms/step - loss: 0.6558 - acc: 0.5895 - val_loss: 0.5475 - val_acc: 0.7408\n",
      "Epoch 2/10\n",
      "6920/6920 [==============================] - 16s 2ms/step - loss: 0.4508 - acc: 0.7919 - val_loss: 0.4838 - val_acc: 0.7672\n",
      "Epoch 3/10\n",
      "6920/6920 [==============================] - 16s 2ms/step - loss: 0.3485 - acc: 0.8509 - val_loss: 0.5330 - val_acc: 0.7626\n",
      "Epoch 4/10\n",
      "6920/6920 [==============================] - 18s 3ms/step - loss: 0.2884 - acc: 0.8795 - val_loss: 0.5712 - val_acc: 0.7764\n",
      "Epoch 5/10\n",
      "6920/6920 [==============================] - 19s 3ms/step - loss: 0.2461 - acc: 0.8999 - val_loss: 0.6313 - val_acc: 0.7741\n",
      "Epoch 6/10\n",
      "6920/6920 [==============================] - 17s 2ms/step - loss: 0.2229 - acc: 0.9120 - val_loss: 0.6438 - val_acc: 0.7695\n",
      "Epoch 7/10\n",
      "6920/6920 [==============================] - 18s 3ms/step - loss: 0.1901 - acc: 0.9234 - val_loss: 0.7258 - val_acc: 0.7523\n",
      "Epoch 8/10\n",
      "6920/6920 [==============================] - 18s 3ms/step - loss: 0.1601 - acc: 0.9406 - val_loss: 0.8448 - val_acc: 0.7603\n",
      "Epoch 9/10\n",
      "6920/6920 [==============================] - 18s 3ms/step - loss: 0.1373 - acc: 0.9494 - val_loss: 0.8193 - val_acc: 0.7638\n",
      "Epoch 10/10\n",
      "6920/6920 [==============================] - 19s 3ms/step - loss: 0.1089 - acc: 0.9623 - val_loss: 0.8618 - val_acc: 0.7603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f990461af28>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/rnn_converge.jpg\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "Now it is your turn to build the models.\n",
    "I ask that you construct the following models:\n",
    "\n",
    "1. A naive Bayes unigram classifer (follow Wang and Manning http://www.aclweb.org/anthology/P/P12/P12-2.pdf#page=118: you should only implement Naive Bayes, not the combined classifer with SVM).\n",
    "2. A logistic regression model over word types (you can implement this as $y = \\sigma(\\sum_i W x_i + b)$) \n",
    "3. A continuous bag-of-word neural network with embeddings (similar to CBOW in Mikolov et al https://arxiv.org/pdf/1301.3781.pdf).\n",
    "4. A simple convolutional neural network (any variant of CNN as described in Kim http://aclweb.org/anthology/D/D14/D14-1181.pdf).\n",
    "5. Your own extensions to these models...\n",
    "\n",
    "[this](https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/) will be useful\n",
    "<br>\n",
    "You can also use pretrained word vectors (https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec)\n",
    "\n",
    "\n",
    "Consult the papers provided for hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Implementation</h3>\n",
    "<h4>Naive Bayes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on validation of Naive Bayes is 77.98 %\n"
     ]
    }
   ],
   "source": [
    "def naive_b(X_train, y_train, X_val):\n",
    "    y_val = np.zeros(X_val.shape[0])\n",
    "    for i, cont in enumerate(X_val):\n",
    "        p0 = 1\n",
    "        p1 = 1\n",
    "        for word in cont:\n",
    "            if word>20: #basically taking out words like 'the'\n",
    "                p0 *= (X_train[y_train == 0] == word).sum()/(y_train==0).sum()\n",
    "                p1 *= (X_train[y_train == 1] == word).sum()/(y_train==1).sum()\n",
    "        if p1>p0:\n",
    "            y_val[i] = 1\n",
    "    return y_val\n",
    "\n",
    "naive_b_pred= naive_b(train_X, train_y, val_X)\n",
    "\n",
    "print(\"The Accuracy on validation of Naive Bayes is\", np.around(accuracy_score(naive_b_pred, val_y)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Logistic Regression</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy score on validation of Log Regression is 76.61 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nitrov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def log_reg(train, val, train_y):\n",
    "    #imports the vectorizer\n",
    "    vecorizer = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', \n",
    "                                encoding='latin-1', ngram_range=(1, 2), \n",
    "                                stop_words='english')\n",
    "    vecorizer.fit_transform(train + val)\n",
    "    #extracts features\n",
    "    feat_train = vecorizer.transform(train).toarray()\n",
    "    feat_val = vecorizer.transform(val).toarray()\n",
    "    #puts them into log regression\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(feat_train, train_y)\n",
    "    #predicts\n",
    "    log_pred = log_reg.predict(feat_val)\n",
    "    return log_pred\n",
    "\n",
    "log_pred = log_reg(sent_train, sent_val, train_y)\n",
    "\n",
    "print(\"The Accuracy score on validation of Log Regression is\", np.around(accuracy_score(log_pred, val_y)*100,2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>CBOW</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_frequencies)\n",
    "embed_size = embedding_vecor_length\n",
    "window_size = 2\n",
    "\n",
    "cbow = Sequential()\n",
    "cbow.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=window_size*2))\n",
    "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)))\n",
    "cbow.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "cbow.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/sst.bin.train\", \"r\") as corpus:\n",
    "    corpus = [sentence for sentence in corpus if sentence.count(' ') >= 2]\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    corpus = tokenizer.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 51513.95791769028\n",
      "1 48134.76326853037\n",
      "2 46267.807652533054\n",
      "3 45518.01332694292\n",
      "4 45064.4727230072\n",
      "5 44704.04887408018\n",
      "6 44378.961128652096\n",
      "7 44082.23743212223\n",
      "8 43816.06518089771\n",
      "9 43579.768104970455\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data(corpus, window_size, vocab_size):\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "\n",
    "    print(epoch, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Simple Convolution Net + LSTM</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_38 (Embedding)     (None, None, 64)          184832    \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, None, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 271,477\n",
      "Trainable params: 271,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 64\n",
    "conv_model = Sequential()\n",
    "conv_model.add(Embedding(word_index, embedding_vecor_length))\n",
    "conv_model.add(Conv1D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu'))\n",
    "conv_model.add(MaxPool1D(pool_size = 2))\n",
    "conv_model.add(LSTM(100))\n",
    "conv_model.add(Dense(1, activation='sigmoid'))\n",
    "conv_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(conv_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6920 samples, validate on 872 samples\n",
      "Epoch 1/20\n",
      "6920/6920 [==============================] - 15s 2ms/step - loss: 0.6347 - acc: 0.6066 - val_loss: 0.5077 - val_acc: 0.7592\n",
      "Epoch 2/20\n",
      "6920/6920 [==============================] - 10s 2ms/step - loss: 0.3896 - acc: 0.8277 - val_loss: 0.4806 - val_acc: 0.7752\n",
      "Epoch 3/20\n",
      "6920/6920 [==============================] - 11s 2ms/step - loss: 0.2758 - acc: 0.8899 - val_loss: 0.5585 - val_acc: 0.7706\n",
      "Epoch 4/20\n",
      "6920/6920 [==============================] - 10s 1ms/step - loss: 0.2200 - acc: 0.9127 - val_loss: 0.5861 - val_acc: 0.7546\n",
      "Epoch 5/20\n",
      "6920/6920 [==============================] - 12s 2ms/step - loss: 0.1534 - acc: 0.9397 - val_loss: 0.6788 - val_acc: 0.7798\n",
      "Epoch 6/20\n",
      "6920/6920 [==============================] - 12s 2ms/step - loss: 0.0973 - acc: 0.9653 - val_loss: 0.8023 - val_acc: 0.7683\n",
      "Epoch 7/20\n",
      "6920/6920 [==============================] - 12s 2ms/step - loss: 0.0679 - acc: 0.9760 - val_loss: 0.9265 - val_acc: 0.7672\n",
      "Epoch 8/20\n",
      "6920/6920 [==============================] - 11s 2ms/step - loss: 0.0494 - acc: 0.9819 - val_loss: 1.0011 - val_acc: 0.7580\n",
      "Epoch 9/20\n",
      "6920/6920 [==============================] - 11s 2ms/step - loss: 0.0309 - acc: 0.9903 - val_loss: 1.2480 - val_acc: 0.7534\n",
      "Epoch 10/20\n",
      "6920/6920 [==============================] - 11s 2ms/step - loss: 0.0360 - acc: 0.9867 - val_loss: 1.1636 - val_acc: 0.7683\n",
      "Epoch 11/20\n",
      "6920/6920 [==============================] - 11s 2ms/step - loss: 0.0255 - acc: 0.9918 - val_loss: 1.3697 - val_acc: 0.7603\n",
      "Epoch 12/20\n",
      "6920/6920 [==============================] - 11s 2ms/step - loss: 0.0281 - acc: 0.9906 - val_loss: 1.2807 - val_acc: 0.7511\n",
      "Epoch 13/20\n",
      "6920/6920 [==============================] - 11s 2ms/step - loss: 0.0172 - acc: 0.9944 - val_loss: 1.3316 - val_acc: 0.7592\n",
      "Epoch 14/20\n",
      "6920/6920 [==============================] - 11s 2ms/step - loss: 0.0229 - acc: 0.9910 - val_loss: 1.2098 - val_acc: 0.7706\n",
      "Epoch 15/20\n",
      "6920/6920 [==============================] - 11s 2ms/step - loss: 0.0145 - acc: 0.9954 - val_loss: 1.3954 - val_acc: 0.7626\n",
      "Epoch 16/20\n",
      "6920/6920 [==============================] - 14s 2ms/step - loss: 0.0113 - acc: 0.9968 - val_loss: 1.2415 - val_acc: 0.7615\n",
      "Epoch 17/20\n",
      "6920/6920 [==============================] - 14s 2ms/step - loss: 0.0127 - acc: 0.9951 - val_loss: 1.2384 - val_acc: 0.7443\n",
      "Epoch 18/20\n",
      "6920/6920 [==============================] - 13s 2ms/step - loss: 0.0084 - acc: 0.9971 - val_loss: 1.3967 - val_acc: 0.7752\n",
      "Epoch 19/20\n",
      "6920/6920 [==============================] - 12s 2ms/step - loss: 0.0195 - acc: 0.9934 - val_loss: 1.1243 - val_acc: 0.7683\n",
      "Epoch 20/20\n",
      "6920/6920 [==============================] - 12s 2ms/step - loss: 0.0108 - acc: 0.9961 - val_loss: 1.2667 - val_acc: 0.7741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f98886b6390>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Custom Extensions</h4>\n",
    "<h5>More Complex ConvNet + LSTM</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_69 (Embedding)     (None, None, 64)          184832    \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, None, 256)         33024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, None, 128)         98432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, None, 64)          41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, None, 32)          16416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, None, 16)          5136      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 100)               46800     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 425,765\n",
      "Trainable params: 425,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import keras.layers\n",
    "from keras import optimizers\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Activation, Lambda\n",
    "from keras.layers import Conv1D, SpatialDropout1D\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.models import Input, Model\n",
    "\n",
    "embedding_vecor_length = 64\n",
    "conv_lstm = Sequential()\n",
    "conv_lstm.add(Embedding(word_index, embedding_vecor_length))\n",
    "conv_lstm.add(Conv1D(filters = 256, kernel_size = 2, padding = 'same', activation = 'relu'))\n",
    "conv_lstm.add(MaxPool1D(pool_size = 2))\n",
    "conv_lstm.add(Conv1D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "conv_lstm.add(MaxPool1D(pool_size = 2))\n",
    "conv_lstm.add(Conv1D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu'))\n",
    "conv_lstm.add(MaxPool1D(pool_size = 2))\n",
    "conv_lstm.add(Dropout(0.4))\n",
    "conv_lstm.add(Conv1D(filters = 32, kernel_size = 8, padding = 'same', activation = 'relu'))\n",
    "conv_lstm.add(MaxPool1D(pool_size = 2))\n",
    "conv_lstm.add(Dropout(0.4))\n",
    "conv_lstm.add(Conv1D(filters = 16, kernel_size = 10, padding = 'same', activation = 'relu'))\n",
    "conv_lstm.add(MaxPool1D(pool_size = 2))\n",
    "conv_lstm.add(LSTM(100))\n",
    "conv_lstm.add(Dense(1, activation='sigmoid'))\n",
    "conv_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(conv_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6920 samples, validate on 872 samples\n",
      "Epoch 1/20\n",
      "6920/6920 [==============================] - 16s 2ms/step - loss: 0.6915 - acc: 0.5175 - val_loss: 0.6761 - val_acc: 0.5092\n",
      "Epoch 2/20\n",
      "6920/6920 [==============================] - 7s 1ms/step - loss: 0.5334 - acc: 0.7259 - val_loss: 0.4896 - val_acc: 0.7672\n",
      "Epoch 3/20\n",
      "6920/6920 [==============================] - 7s 1ms/step - loss: 0.3453 - acc: 0.8519 - val_loss: 0.4821 - val_acc: 0.7787\n",
      "Epoch 4/20\n",
      "6920/6920 [==============================] - 8s 1ms/step - loss: 0.2680 - acc: 0.8906 - val_loss: 0.5182 - val_acc: 0.7683\n",
      "Epoch 5/20\n",
      "6920/6920 [==============================] - 7s 1ms/step - loss: 0.2208 - acc: 0.9159 - val_loss: 0.5129 - val_acc: 0.7764\n",
      "Epoch 6/20\n",
      "6920/6920 [==============================] - 7s 1ms/step - loss: 0.1728 - acc: 0.9354 - val_loss: 0.5616 - val_acc: 0.7752\n",
      "Epoch 7/20\n",
      "6920/6920 [==============================] - 8s 1ms/step - loss: 0.1414 - acc: 0.9474 - val_loss: 0.6492 - val_acc: 0.7649\n",
      "Epoch 8/20\n",
      "6920/6920 [==============================] - 7s 1ms/step - loss: 0.1114 - acc: 0.9598 - val_loss: 0.6495 - val_acc: 0.7638\n",
      "Epoch 9/20\n",
      "6920/6920 [==============================] - 10s 1ms/step - loss: 0.0932 - acc: 0.9668 - val_loss: 0.7449 - val_acc: 0.7672\n",
      "Epoch 10/20\n",
      "6920/6920 [==============================] - 8s 1ms/step - loss: 0.0658 - acc: 0.9763 - val_loss: 0.8105 - val_acc: 0.7626\n",
      "Epoch 11/20\n",
      "6920/6920 [==============================] - 7s 1ms/step - loss: 0.0615 - acc: 0.9769 - val_loss: 0.7893 - val_acc: 0.7672\n",
      "Epoch 12/20\n",
      "6920/6920 [==============================] - 7s 1ms/step - loss: 0.0530 - acc: 0.9802 - val_loss: 0.8751 - val_acc: 0.7718\n",
      "Epoch 13/20\n",
      "6920/6920 [==============================] - 8s 1ms/step - loss: 0.0448 - acc: 0.9832 - val_loss: 0.8871 - val_acc: 0.7638\n",
      "Epoch 14/20\n",
      "6920/6920 [==============================] - 7s 1ms/step - loss: 0.0344 - acc: 0.9873 - val_loss: 0.9986 - val_acc: 0.7580\n",
      "Epoch 15/20\n",
      "6920/6920 [==============================] - 7s 1ms/step - loss: 0.0314 - acc: 0.9887 - val_loss: 1.0745 - val_acc: 0.7592\n",
      "Epoch 16/20\n",
      "6920/6920 [==============================] - 8s 1ms/step - loss: 0.0197 - acc: 0.9932 - val_loss: 1.2009 - val_acc: 0.7638\n",
      "Epoch 17/20\n",
      "6920/6920 [==============================] - 7s 1ms/step - loss: 0.0215 - acc: 0.9921 - val_loss: 1.2174 - val_acc: 0.7534\n",
      "Epoch 18/20\n",
      "6920/6920 [==============================] - 8s 1ms/step - loss: 0.0286 - acc: 0.9896 - val_loss: 1.0967 - val_acc: 0.7569\n",
      "Epoch 19/20\n",
      "6920/6920 [==============================] - 8s 1ms/step - loss: 0.0222 - acc: 0.9928 - val_loss: 1.1204 - val_acc: 0.7431\n",
      "Epoch 20/20\n",
      "6920/6920 [==============================] - 8s 1ms/step - loss: 0.0150 - acc: 0.9948 - val_loss: 1.2789 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9875e18f98>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_lstm.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=20, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
