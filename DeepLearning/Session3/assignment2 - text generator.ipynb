{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to build language generative model on Armenian text. This is a great [blogpost](https://machinelearningmastery.com/gentle-introduction-generative-long-short-term-memory-networks/) on generative models, so look through it at first.\n",
    "You should:\n",
    "* collect data<br>\n",
    "you can collect it from anywhere, it's up to you. I can suggest some sources, such as:\n",
    "    - [https://hy.wikisource.org/wiki/%D4%BF%D5%A1%D5...](https://hy.wikisource.org/wiki/%D4%BF%D5%A1%D5%BF%D5%A5%D5%A3%D5%B8%D6%80%D5%AB%D5%A1:%D5%80%D5%B8%D5%BE%D5%B0%D5%A1%D5%B6%D5%B6%D5%A5%D5%BD_%D4%B9%D5%B8%D6%82%D5%B4%D5%A1%D5%B6%D5%B5%D5%A1%D5%B6%D5%AB_%D5%B0%D5%A5%D6%84%D5%AB%D5%A1%D5%A9%D5%B6%D5%A5%D6%80)\n",
    "    - [http://grapaharan.org/%D4%BF%D5%A1%D5%BF%...](http://grapaharan.org/%D4%BF%D5%A1%D5%BF%D5%A5%D5%A3%D5%B8%D6%80%D5%AB%D5%A1:%D5%80%D5%A5%D6%84%D5%AB%D5%A1%D5%A9)\n",
    "* preprocess data\n",
    "* find word embeddings (or train it simultaneously with the model)\n",
    "* build a model and train it\n",
    "* impress me with creative sentences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"stories.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = raw_text.replace('՞','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = raw_text.replace('։','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = raw_text.replace('՜','')\n",
    "raw_text = raw_text.replace(',','')\n",
    "raw_text = raw_text.replace('․','')\n",
    "raw_text = raw_text.replace('«','')\n",
    "raw_text = raw_text.replace('»','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  203114\n",
      "Total Vocab:  74\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  203014\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100, 256)          264192    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 74)                19018     \n",
      "=================================================================\n",
      "Total params: 808,522\n",
      "Trainable params: 808,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "203014/203014 [==============================] - 1860s 9ms/step - loss: 2.9761\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.97606, saving model to weights/weights-01-2.9761.hdf5\n",
      "Epoch 2/20\n",
      "203014/203014 [==============================] - 1626s 8ms/step - loss: 2.6895\n",
      "\n",
      "Epoch 00002: loss improved from 2.97606 to 2.68954, saving model to weights/weights-02-2.6895.hdf5\n",
      "Epoch 3/20\n",
      "203014/203014 [==============================] - 1613s 8ms/step - loss: 2.5372\n",
      "\n",
      "Epoch 00003: loss improved from 2.68954 to 2.53720, saving model to weights/weights-03-2.5372.hdf5\n",
      "Epoch 4/20\n",
      "203014/203014 [==============================] - 1613s 8ms/step - loss: 2.4275\n",
      "\n",
      "Epoch 00004: loss improved from 2.53720 to 2.42751, saving model to weights/weights-04-2.4275.hdf5\n",
      "Epoch 5/20\n",
      "203014/203014 [==============================] - 1617s 8ms/step - loss: 2.3404\n",
      "\n",
      "Epoch 00005: loss improved from 2.42751 to 2.34044, saving model to weights/weights-05-2.3404.hdf5\n",
      "Epoch 6/20\n",
      "203014/203014 [==============================] - 1622s 8ms/step - loss: 2.2730\n",
      "\n",
      "Epoch 00006: loss improved from 2.34044 to 2.27297, saving model to weights/weights-06-2.2730.hdf5\n",
      "Epoch 7/20\n",
      "203014/203014 [==============================] - 1625s 8ms/step - loss: 2.2163\n",
      "\n",
      "Epoch 00007: loss improved from 2.27297 to 2.21633, saving model to weights/weights-07-2.2163.hdf5\n",
      "Epoch 8/20\n",
      "203014/203014 [==============================] - 1629s 8ms/step - loss: 2.1694\n",
      "\n",
      "Epoch 00008: loss improved from 2.21633 to 2.16938, saving model to weights/weights-08-2.1694.hdf5\n",
      "Epoch 9/20\n",
      "203014/203014 [==============================] - 1630s 8ms/step - loss: 2.1283\n",
      "\n",
      "Epoch 00009: loss improved from 2.16938 to 2.12830, saving model to weights/weights-09-2.1283.hdf5\n",
      "Epoch 10/20\n",
      "203014/203014 [==============================] - 1632s 8ms/step - loss: 2.0950\n",
      "\n",
      "Epoch 00010: loss improved from 2.12830 to 2.09498, saving model to weights/weights-10-2.0950.hdf5\n",
      "Epoch 11/20\n",
      "203014/203014 [==============================] - 1642s 8ms/step - loss: 2.0642\n",
      "\n",
      "Epoch 00011: loss improved from 2.09498 to 2.06417, saving model to weights/weights-11-2.0642.hdf5\n",
      "Epoch 12/20\n",
      "203014/203014 [==============================] - 1631s 8ms/step - loss: 2.0364\n",
      "\n",
      "Epoch 00012: loss improved from 2.06417 to 2.03642, saving model to weights/weights-12-2.0364.hdf5\n",
      "Epoch 13/20\n",
      "203014/203014 [==============================] - 1635s 8ms/step - loss: 2.0092\n",
      "\n",
      "Epoch 00013: loss improved from 2.03642 to 2.00918, saving model to weights/weights-13-2.0092.hdf5\n",
      "Epoch 14/20\n",
      "203014/203014 [==============================] - 1649s 8ms/step - loss: 1.9875\n",
      "\n",
      "Epoch 00014: loss improved from 2.00918 to 1.98745, saving model to weights/weights-14-1.9875.hdf5\n",
      "Epoch 15/20\n",
      "203014/203014 [==============================] - 1655s 8ms/step - loss: 1.9666\n",
      "\n",
      "Epoch 00015: loss improved from 1.98745 to 1.96660, saving model to weights/weights-15-1.9666.hdf5\n",
      "Epoch 16/20\n",
      "203014/203014 [==============================] - 1643s 8ms/step - loss: 1.9441\n",
      "\n",
      "Epoch 00016: loss improved from 1.96660 to 1.94414, saving model to weights/weights-16-1.9441.hdf5\n",
      "Epoch 17/20\n",
      "203014/203014 [==============================] - 1642s 8ms/step - loss: 1.9240\n",
      "\n",
      "Epoch 00017: loss improved from 1.94414 to 1.92401, saving model to weights/weights-17-1.9240.hdf5\n",
      "Epoch 18/20\n",
      "203014/203014 [==============================] - 1704s 8ms/step - loss: 1.9108\n",
      "\n",
      "Epoch 00018: loss improved from 1.92401 to 1.91078, saving model to weights/weights-18-1.9108.hdf5\n",
      "Epoch 19/20\n",
      "203014/203014 [==============================] - 1875s 9ms/step - loss: 1.8927\n",
      "\n",
      "Epoch 00019: loss improved from 1.91078 to 1.89274, saving model to weights/weights-19-1.8927.hdf5\n",
      "Epoch 20/20\n",
      "203014/203014 [==============================] - 1802s 9ms/step - loss: 1.8777\n",
      "\n",
      "Epoch 00020: loss improved from 1.89274 to 1.87772, saving model to weights/weights-20-1.8777.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7eff9f85c588>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights/weights-20-1.8777.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" երկար սև պարեգոտը մադամ մալբինը հարրիին կանգնեցրեց տղայի կողքին ՝ մեկ ուրիշ աթոռակի վրա հարրիի գլխով \"\n",
      " անցած մի բան չէ կարող եր անն էր որ նա անհանգիստ աննպաս հարու համար աննպաս մարդ էր այն արալի անաամ մարդ առան մեջ մակատի մեջ մակատի մեծ կարարել էր որ նա արաե կարարել էր որ նա արաե կարարել էր որ նա արաե կարարել էր որ նա արաե կարարել էր որ նա արաե կարար\"\n",
      "The fanfic-inator's quest has been completed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(250):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print (\"\\\"\")\n",
    "print (\"The fanfic-inator's quest has been completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
